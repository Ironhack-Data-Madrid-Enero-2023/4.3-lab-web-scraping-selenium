{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Lab\n",
    "\n",
    "You will find in this notebook some scrapy exercises to practise your scraping skills.\n",
    "\n",
    "**Tips:**\n",
    "\n",
    "- Check the response status code for each request to ensure you have obtained the intended contennt.\n",
    "- Print the response text in each request to understand the kind of info you are getting and its format.\n",
    "- Check for patterns in the response text to extract the data/info requested in each question.\n",
    "- Visit each url and take a look at its source through Chrome DevTools. You'll need to identify the html tags, special class names etc. used for the html content you are expected to extract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Selenium Doc](https://www.selenium.dev/documentation/)\n",
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide) documentation \n",
    "- [Urllib](https://docs.python.org/3/library/urllib.html#module-urllib)\n",
    "- [re lib](https://docs.python.org/3/library/re.html)\n",
    "- [lxml lib](https://lxml.de/)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below are the libraries and modules you may need. `Selenium` and `pandas` are imported for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver-manager in c:\\users\\axell\\anaconda3\\anaconda3\\lib\\site-packages (3.8.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\axell\\anaconda3\\anaconda3\\lib\\site-packages (from webdriver-manager) (4.64.1)\n",
      "Requirement already satisfied: requests in c:\\users\\axell\\anaconda3\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.28.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\axell\\anaconda3\\anaconda3\\lib\\site-packages (from webdriver-manager) (21.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\axell\\anaconda3\\anaconda3\\lib\\site-packages (from webdriver-manager) (0.21.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\axell\\anaconda3\\anaconda3\\lib\\site-packages (from packaging->webdriver-manager) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\axell\\anaconda3\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\axell\\anaconda3\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\axell\\anaconda3\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\axell\\anaconda3\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\axell\\anaconda3\\anaconda3\\lib\\site-packages (from tqdm->webdriver-manager) (0.4.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install webdriver-manager\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager # sustituye al archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enable the options you may need. In the next cell you have an example of them but you can choose to use them or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\axell\\AppData\\Local\\Temp\\ipykernel_1952\\4076755805.py:6: DeprecationWarning: headless property is deprecated, instead use add_argument('--headless') or add_argument('--headless=new')\n",
      "  opciones.headless=False    # si True, no aperece la ventana (headless=no visible)\n"
     ]
    }
   ],
   "source": [
    "#driver configuration\n",
    "opciones=Options()\n",
    "\n",
    "opciones.add_experimental_option('excludeSwitches', ['enable-automation'])\n",
    "opciones.add_experimental_option('useAutomationExtension', False)\n",
    "opciones.headless=False    # si True, no aperece la ventana (headless=no visible)\n",
    "opciones.add_argument('--start-maximized')         # comienza maximizado\n",
    "#opciones.add_argument('user-data-dir=selenium')    # mantiene las cookies\n",
    "#opciones.add_extension('driver_folder/adblock.crx')       # adblocker\n",
    "opciones.add_argument('--incognito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By # By es para buscar por tag, clase, id...\n",
    "\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver = \"./chromedriver.exe\" #remember substitute this for your driver path\n",
    "#driver = webdriver.Chrome(driver,options = opciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\axell\\AppData\\Local\\Temp\\ipykernel_1952\\24426078.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(PATH)       # abre una venta una de chrome\n"
     ]
    }
   ],
   "source": [
    "PATH = ChromeDriverManager().install()     # instala el driver de chrome\n",
    "\n",
    "driver=webdriver.Chrome(PATH)       # abre una venta una de chrome\n",
    "\n",
    "driver.get('https://www.google.es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download, parse, and print the content from the Trending Developers page from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\axell\\AppData\\Local\\Temp\\ipykernel_1952\\3534757676.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(PATH)\n"
     ]
    }
   ],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "PATH = ChromeDriverManager().install()\n",
    "driver=webdriver.Chrome(PATH) \n",
    "url = 'https://github.com/trending/developers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Skip to content\\nSign up\\nExplore\\nTopics\\nTrending\\nCollections\\nEvents\\nGitHub Sponsors\\nGet email updates\\nTrending\\nThese are the developers building the hot tools today.\\nRepositories\\nDevelopers\\nLanguage: Any\\nDate range: Today\\nSponsorable: All\\n1\\nAriel Mashraki\\na8m\\nPOPULAR REPO\\ngolang-cheat-sheet\\nAn overview of Go syntax and features.\\nFollow\\n2\\nMattias Wadman\\nwader\\nPOPULAR REPO\\nfq\\njq for binary formats - tool, language and decoders for working with binary and text formats\\nFollow\\n3\\nHenrik Rydgård\\nhrydgard\\nPOPULAR REPO\\nppsspp\\nA PSP emulator for Android, Windows, Mac and Linux, written in C++. Want to contribute? Join us on Discord at https://discord.gg/5NJB6dD …\\nFollow\\n4\\nMark Tyneway\\ntynes\\nop labs @ optimism\\nFollow\\n5\\nLincoln Stein\\nlstein\\nPOPULAR REPO\\nNet-ISP-Balance\\nSet of scripts to load-balance your Internet connection across two or more ISPs with auto failover\\nFollow\\n6\\njxxghp\\njxxghp\\nPOPULAR REPO\\nnas-tools\\nNAS媒体库资源归集、整理自动化工具\\nFollow\\n7\\nPaul Razvan Berg\\nPaulRBerg\\nPOPULAR REPO\\nfoundry-template\\nFoundry-based template for developing Solidity smart contracts\\nFollow\\n8\\nFlorian Roth\\nNeo23x0\\nPOPULAR REPO\\ntiny-shells\\nAll kinds of tiny shells\\nFollow\\n9\\nMichaIng\\nPOPULAR REPO\\nDietPi\\nLightweight justice for your single-board computer!\\nFollow\\n10\\nVectorized\\nVectorized\\nPOPULAR REPO\\nsolady\\nOptimized Solidity snippets.\\nFollow\\n11\\nLianmin Zheng\\nmerrymercy\\nPOPULAR REPO\\nawesome-tensor-compilers\\nA list of awesome compiler projects and papers for tensor computation and deep learning.\\nFollow\\n12\\nX.\\nije\\nPOPULAR REPO\\nesm.sh\\nA fast, global CDN for NPM packages with ESM format.\\nFollow\\n13\\nNorbert de Langen\\nndelangen\\nChroma Software\\nFollow\\n14\\nStefan Prodan\\nstefanprodan\\nPOPULAR REPO\\npodinfo\\nGo microservice template for Kubernetes\\nFollow\\n15\\nJaco\\njacogr\\nPOPULAR REPO\\nsubstrate-ledger-ed25519\\nExtract Substrate and Polkadot compatible ed25519 keys from Ledger mnemonic phrases\\nFollow\\n16\\nFrançois Chollet\\nfchollet\\nPOPULAR REPO\\nnamex\\nClean up the public namespace of your package!\\nFollow\\n17\\nMichał Lytek\\nMichalLytek\\nPOPULAR REPO\\ntype-graphql\\nCreate GraphQL schema and resolvers with TypeScript, using classes and decorators!\\nFollow\\n18\\nLukas Taegert-Atkinson\\nlukastaegert\\nPOPULAR REPO\\nviteconf22-rollup\\nFollow\\n19\\nBen McCann\\nbenmccann\\nPOPULAR REPO\\nesm-env\\nFollow\\n20\\nAntonio Cheong\\nacheong08\\nPOPULAR REPO\\nChatGPT\\nReverse engineered ChatGPT API\\nFollow\\n21\\nMaarten Grootendorst\\nMaartenGr\\nPOPULAR REPO\\nBERTopic\\nLeveraging BERT and c-TF-IDF to create easily interpretable topics.\\nFollow\\n22\\nLeon\\nultrafunkamsterdam\\nPOPULAR REPO\\nundetected-chromedriver\\nCustom Selenium Chromedriver | Zero-Config | Passes ALL bot mitigation systems (like Distil / Imperva/ Datadadome / CloudFlare IUAM)\\nFollow\\n23\\nsyuilo\\nsyuilo\\nPOPULAR REPO\\naiscript\\n🔋 A lightweight scripting language runing on JavaScript\\nFollow\\n24\\nAbhinav Gupta\\nabhinav\\nPOPULAR REPO\\ntmux-fastcopy\\neasymotion-style text copying for tmux.\\nFollow\\n25\\nYair Morgenstern\\nyairm210\\nPOPULAR REPO\\nUnciv\\nOpen-source Android/Desktop remake of Civ V\\nFollow\\nFooter\\n© 2023 GitHub, Inc.\\nFooter navigation\\nTerms\\nPrivacy\\nSecurity\\nStatus\\nDocs\\nContact GitHub\\nPricing\\nAPI\\nTraining\\nBlog\\nAbout'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.find_element(By.XPATH, '/html').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the names of the trending developers retrieved in the previous step.\n",
    "\n",
    "Your output should be a Python list of developer names. Each name should not contain any html tag.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Find out the html tag and class names used for the developer names.\n",
    "\n",
    "1. Use string manipulation techniques to replace whitespaces and linebreaks (i.e. `\\n`) in the *text* of each html element. Use a list to store the clean names.\n",
    "\n",
    "1. Print the list of names.\n",
    "\n",
    "Your output should look like below:\n",
    "\n",
    "```\n",
    "['trimstray (@trimstray)',\n",
    " 'joewalnes (JoeWalnes)',\n",
    " 'charlax (Charles-AxelDein)',\n",
    " 'ForrestKnight (ForrestKnight)',\n",
    " 'revery-ui (revery-ui)',\n",
    " 'alibaba (Alibaba)',\n",
    " 'Microsoft (Microsoft)',\n",
    " 'github (GitHub)',\n",
    " 'facebook (Facebook)',\n",
    " 'boazsegev (Bo)',\n",
    " 'google (Google)',\n",
    " 'cloudfetch',\n",
    " 'sindresorhus (SindreSorhus)',\n",
    " 'tensorflow',\n",
    " 'apache (TheApacheSoftwareFoundation)',\n",
    " 'DevonCrawford (DevonCrawford)',\n",
    " 'ARMmbed (ArmMbed)',\n",
    " 'vuejs (vuejs)',\n",
    " 'fastai (fast.ai)',\n",
    " 'QiShaoXuan (Qi)',\n",
    " 'joelparkerhenderson (JoelParkerHenderson)',\n",
    " 'torvalds (LinusTorvalds)',\n",
    " 'CyC2018',\n",
    " 'komeiji-satori (神楽坂覚々)',\n",
    " 'script-8']\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [e.text.strip() for e in driver.find_elements(By.XPATH, '//*/div[2]/div[1]/div[1]/h1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ariel Mashraki',\n",
       " 'Mattias Wadman',\n",
       " 'Henrik Rydgård',\n",
       " 'Mark Tyneway',\n",
       " 'Lincoln Stein']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the trending Python repositories in GitHub\n",
    "\n",
    "The steps to solve this problem is similar to the previous one except that you need to find out the repository names instead of developer names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "PATH = ChromeDriverManager().install()\n",
    "\n",
    "driver=webdriver.Chrome(PATH) \n",
    "\n",
    "url = 'https://github.com/trending/python?since=daily'\n",
    "\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [e.text.strip() for e in driver.find_elements(By.XPATH, '/html/body/div[1]/div[4]/main/div[3]/div/div[2]/article/h1/a')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acheong08 / ChatGPT',\n",
       " 'Zero6992 / chatGPT-discord-bot',\n",
       " 'TheAlgorithms / Python',\n",
       " 'LAION-AI / Open-Assistant',\n",
       " 'ddPn08 / Lsmith',\n",
       " 'zhayujie / chatgpt-on-wechat',\n",
       " 'LeagueOfPoro / CapsuleFarmerEvolved',\n",
       " 'microsoft / BioGPT',\n",
       " 'BlinkDL / ChatRWKV',\n",
       " 'AIGCT / EASYChatGPT',\n",
       " 'mmz-001 / knowledge_gpt',\n",
       " 'jxxghp / nas-tools',\n",
       " 'tiangolo / fastapi',\n",
       " 'TomSchimansky / CustomTkinter',\n",
       " 'Rudrabha / Wav2Lip',\n",
       " 'public-apis / public-apis',\n",
       " 'biancangming / wtv',\n",
       " 'chidiwilliams / buzz',\n",
       " 'bellingcat / octosuite',\n",
       " 'approximatelabs / sketch',\n",
       " 'yerfor / GeneFace',\n",
       " 'uptrain-ai / uptrain',\n",
       " 'facebookresearch / metaseq',\n",
       " 'lss233 / chatgpt-mirai-qq-bot',\n",
       " 'ansible / ansible']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display all the image links from Walt Disney wikipedia page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "\n",
    "PATH = ChromeDriverManager().install()\n",
    "\n",
    "driver=webdriver.Chrome(PATH) \n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/Walt_Disney'\n",
    "\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import requests as req\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [e.get_attribute('src') for e in driver.find_elements(By.TAG_NAME, 'img')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://en.wikipedia.org/static/images/icons/wikipedia.png',\n",
       " 'https://en.wikipedia.org/static/images/mobile/copyright/wikipedia-wordmark-en.svg',\n",
       " 'https://en.wikipedia.org/static/images/mobile/copyright/wikipedia-tagline-en.svg',\n",
       " 'https://upload.wikimedia.org/wikipedia/en/thumb/e/e7/Cscr-featured.svg/20px-Cscr-featured.svg.png',\n",
       " 'https://upload.wikimedia.org/wikipedia/en/thumb/8/8c/Extended-protection-shackle.svg/20px-Extended-protection-shackle.svg.png']"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/df/Walt_Disney_1946.JPG/220px-Walt_Disney_1946.JPG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url =lst[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve an arbitary Wikipedia page of \"Python\" and create a list of links on that page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url ='https://en.wikipedia.org/wiki/Python' \n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [e.get_attribute('href') for e in driver.find_elements(By.TAG_NAME, 'a')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://en.wikipedia.org/wiki/Python#bodyContent',\n",
       " 'https://en.wikipedia.org/wiki/Main_Page',\n",
       " 'https://en.wikipedia.org/wiki/Special:Search']"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Titles that have changed in the United States Code since its last release point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'http://uscode.house.gov/download/download.shtml'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [e.text for e in driver.find_elements(By.XPATH, '//div[@class=\"usctitlechanged\"]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'/' importa el orden, el elemento siguiente sigue el anterior\n",
      "'//' No importa lo que haya entre los dos elementos (el anterior y el siguiente)\n",
      "\n",
      "ej: '//div[@class=\"usctitlechanged\"]'\n",
      "no importa lo pasado. Luego en el tag div. Busca la @class ''.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('''\n",
    "'/' importa el orden, el elemento siguiente sigue el anterior\n",
    "'//' No importa lo que haya entre los dos elementos (el anterior y el siguiente)\n",
    "\n",
    "ej: '//div[@class=\"usctitlechanged\"]'\n",
    "no importa lo pasado. Luego en el tag div. Busca la @class ''.\n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Python list with the top ten FBI's Most Wanted names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.fbi.gov/wanted/topten'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [e.text for e in driver.find_elements(By.XPATH, '//h3[@class=\"title\"]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.emsc-csem.org/Earthquake/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = [e.text[:10] for e in driver.find_elements(By.XPATH, '//table//*[@class=\"tabev6\"]')]\n",
    "time = [e.text[13:23] for e in driver.find_elements(By.XPATH, '//table//*[@class=\"tabev6\"]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude = [e.text for e in driver.find_elements(By.XPATH, '//table//*[@class=\"tabev1\"]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = latitude[::2]\n",
    "lon = latitude[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = [e.text for e in driver.find_elements(By.XPATH, '//table//*[@class=\"tabev3\"]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = [e.text for e in driver.find_elements(By.XPATH, '//table//*[@class=\"tb_region\"]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {\n",
    "'date' : date,\n",
    "'time': time,\n",
    "'depth':depth,\n",
    "'region' : region,\n",
    "'latitude': lat,\n",
    "'longitude' : lon\n",
    "    \n",
    "}\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>depth</th>\n",
       "      <th>region</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-02-08</td>\n",
       "      <td>16:01:57.0</td>\n",
       "      <td>2</td>\n",
       "      <td>SULAWESI, INDONESIA</td>\n",
       "      <td>4.92</td>\n",
       "      <td>122.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-08</td>\n",
       "      <td>15:56:50.9</td>\n",
       "      <td>11</td>\n",
       "      <td>CENTRAL TURKEY</td>\n",
       "      <td>37.32</td>\n",
       "      <td>37.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-02-08</td>\n",
       "      <td>15:51:45.0</td>\n",
       "      <td>10</td>\n",
       "      <td>NEAR N COAST OF PAPUA, INDONESIA</td>\n",
       "      <td>2.52</td>\n",
       "      <td>140.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-02-08</td>\n",
       "      <td>15:49:59.4</td>\n",
       "      <td>45</td>\n",
       "      <td>CENTRAL TURKEY</td>\n",
       "      <td>37.84</td>\n",
       "      <td>36.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-02-08</td>\n",
       "      <td>15:42:47.8</td>\n",
       "      <td>4</td>\n",
       "      <td>CENTRAL TURKEY</td>\n",
       "      <td>37.05</td>\n",
       "      <td>36.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-02-08</td>\n",
       "      <td>15:40:34.0</td>\n",
       "      <td>1</td>\n",
       "      <td>CENTRAL TURKEY</td>\n",
       "      <td>37.23</td>\n",
       "      <td>36.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-02-08</td>\n",
       "      <td>15:32:41.5</td>\n",
       "      <td>10</td>\n",
       "      <td>KENYA</td>\n",
       "      <td>4.85</td>\n",
       "      <td>39.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-02-08</td>\n",
       "      <td>15:29:29.0</td>\n",
       "      <td>33</td>\n",
       "      <td>ISLA CHILOE, LOS LAGOS, CHILE</td>\n",
       "      <td>42.05</td>\n",
       "      <td>73.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-02-08</td>\n",
       "      <td>15:28:32.1</td>\n",
       "      <td>7</td>\n",
       "      <td>EASTERN TURKEY</td>\n",
       "      <td>38.15</td>\n",
       "      <td>38.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-02-08</td>\n",
       "      <td>15:25:58.3</td>\n",
       "      <td>5</td>\n",
       "      <td>EASTERN TURKEY</td>\n",
       "      <td>39.02</td>\n",
       "      <td>40.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-02-08</td>\n",
       "      <td>15:23:04.7</td>\n",
       "      <td>10</td>\n",
       "      <td>EASTERN TURKEY</td>\n",
       "      <td>37.58</td>\n",
       "      <td>38.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-02-08</td>\n",
       "      <td>15:22:32.2</td>\n",
       "      <td>89</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "      <td>19.17</td>\n",
       "      <td>155.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-02-08</td>\n",
       "      <td>15:21:31.8</td>\n",
       "      <td>4</td>\n",
       "      <td>EASTERN TURKEY</td>\n",
       "      <td>39.14</td>\n",
       "      <td>40.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-02-08</td>\n",
       "      <td>15:16:17.8</td>\n",
       "      <td>24</td>\n",
       "      <td>OFFSHORE HONDURAS</td>\n",
       "      <td>16.76</td>\n",
       "      <td>86.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-02-08</td>\n",
       "      <td>15:11:13.0</td>\n",
       "      <td>6</td>\n",
       "      <td>EASTERN TURKEY</td>\n",
       "      <td>38.12</td>\n",
       "      <td>38.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-02-08</td>\n",
       "      <td>15:07:23.8</td>\n",
       "      <td>5</td>\n",
       "      <td>CENTRAL TURKEY</td>\n",
       "      <td>38.54</td>\n",
       "      <td>37.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-02-08</td>\n",
       "      <td>15:04:43.1</td>\n",
       "      <td>6</td>\n",
       "      <td>CENTRAL TURKEY</td>\n",
       "      <td>38.04</td>\n",
       "      <td>37.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023-02-08</td>\n",
       "      <td>15:00:05.9</td>\n",
       "      <td>131</td>\n",
       "      <td>CENTRAL TURKEY</td>\n",
       "      <td>38.12</td>\n",
       "      <td>37.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-02-08</td>\n",
       "      <td>14:57:46.4</td>\n",
       "      <td>5</td>\n",
       "      <td>CENTRAL TURKEY</td>\n",
       "      <td>37.30</td>\n",
       "      <td>37.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2023-02-08</td>\n",
       "      <td>14:55:50.9</td>\n",
       "      <td>3</td>\n",
       "      <td>EASTERN TURKEY</td>\n",
       "      <td>38.11</td>\n",
       "      <td>38.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date        time depth                             region latitude  \\\n",
       "0   2023-02-08  16:01:57.0     2                SULAWESI, INDONESIA    4.92    \n",
       "1   2023-02-08  15:56:50.9    11                     CENTRAL TURKEY   37.32    \n",
       "2   2023-02-08  15:51:45.0    10   NEAR N COAST OF PAPUA, INDONESIA    2.52    \n",
       "3   2023-02-08  15:49:59.4    45                     CENTRAL TURKEY   37.84    \n",
       "4   2023-02-08  15:42:47.8     4                     CENTRAL TURKEY   37.05    \n",
       "5   2023-02-08  15:40:34.0     1                     CENTRAL TURKEY   37.23    \n",
       "6   2023-02-08  15:32:41.5    10                              KENYA    4.85    \n",
       "7   2023-02-08  15:29:29.0    33      ISLA CHILOE, LOS LAGOS, CHILE   42.05    \n",
       "8   2023-02-08  15:28:32.1     7                     EASTERN TURKEY   38.15    \n",
       "9   2023-02-08  15:25:58.3     5                     EASTERN TURKEY   39.02    \n",
       "10  2023-02-08  15:23:04.7    10                     EASTERN TURKEY   37.58    \n",
       "11  2023-02-08  15:22:32.2    89           ISLAND OF HAWAII, HAWAII   19.17    \n",
       "12  2023-02-08  15:21:31.8     4                     EASTERN TURKEY   39.14    \n",
       "13  2023-02-08  15:16:17.8    24                  OFFSHORE HONDURAS   16.76    \n",
       "14  2023-02-08  15:11:13.0     6                     EASTERN TURKEY   38.12    \n",
       "15  2023-02-08  15:07:23.8     5                     CENTRAL TURKEY   38.54    \n",
       "16  2023-02-08  15:04:43.1     6                     CENTRAL TURKEY   38.04    \n",
       "17  2023-02-08  15:00:05.9   131                     CENTRAL TURKEY   38.12    \n",
       "18  2023-02-08  14:57:46.4     5                     CENTRAL TURKEY   37.30    \n",
       "19  2023-02-08  14:55:50.9     3                     EASTERN TURKEY   38.11    \n",
       "\n",
       "   longitude  \n",
       "0    122.66   \n",
       "1     37.07   \n",
       "2    140.68   \n",
       "3     36.61   \n",
       "4     36.63   \n",
       "5     36.96   \n",
       "6     39.43   \n",
       "7     73.92   \n",
       "8     38.34   \n",
       "9     40.81   \n",
       "10    38.06   \n",
       "11   155.49   \n",
       "12    40.15   \n",
       "13    86.10   \n",
       "14    38.26   \n",
       "15    37.76   \n",
       "16    37.04   \n",
       "17    37.24   \n",
       "18    37.05   \n",
       "19    38.53   "
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df).sort_values('time', ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count number of tweets by a given Twitter account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to include a ***try/except block*** for account names not found. \n",
    "<br>***Hint:*** the program should count the number of tweets for any provided account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/dergigi'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['70.4K Tweets']"
      ]
     },
     "execution_count": 735,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = [e.text for e in driver.find_elements(By.XPATH, '//div[@class =\"css-901oao css-1hf3ou5 r-14j79pv r-37j5jr r-n6v787 r-16dba41 r-1cwl3u0 r-bcqeeo r-qvutc0\"]')]\n",
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of followers of a given twitter account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to include a ***try/except block*** in case account/s name not found. \n",
    "<br>***Hint:*** the program should count the followers for any provided account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/dergigi'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1952\\2111297700.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfollowers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'//span[@class =\"css-901oao css-16my406 r-18jsvk2 r-poiln3 r-1b43r93 r-b88u0q r-1cwl3u0 r-bcqeeo r-qvutc0\"]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfollowers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "followers = [e.text for e in driver.find_elements(By.XPATH, '//span[@class =\"css-901oao css-16my406 r-18jsvk2 r-poiln3 r-1b43r93 r-b88u0q r-1cwl3u0 r-bcqeeo r-qvutc0\"]')]\n",
    "followers[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List all language names and number of related articles in the order they appear in wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "\n",
    "PATH = ChromeDriverManager().install()\n",
    "\n",
    "driver=webdriver.Chrome(PATH) \n",
    "\n",
    "url = 'https://www.wikipedia.org/'\n",
    "\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = [e.text for e in driver.find_elements(By.XPATH, '//*[@class =\"link-box\"]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['English\\n6 606 000+ articles',\n",
       " 'Русский\\n1 887 000+ статей',\n",
       " '日本語\\n1 359 000+ 記事',\n",
       " 'Deutsch\\n2 764 000+ Artikel',\n",
       " 'Français\\n2 488 000+ articles',\n",
       " 'Español\\n1 833 000+ artículos',\n",
       " 'Italiano\\n1 792 000+ voci',\n",
       " 'فارسی\\n947 000+ مقاله',\n",
       " 'Polski\\n1 552 000+ haseł']"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A list with the different kind of datasets available in data.gov.uk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://data.gov.uk/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = [e.text for e in driver.find_elements(By.XPATH, '//*[@class =\"govuk-link\"]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Business and economy',\n",
       " 'Crime and justice',\n",
       " 'Defence',\n",
       " 'Education',\n",
       " 'Environment',\n",
       " 'Government',\n",
       " 'Government spending',\n",
       " 'Health',\n",
       " 'Mapping',\n",
       " 'Society',\n",
       " 'Towns and cities',\n",
       " 'Transport',\n",
       " 'Digital service performance',\n",
       " 'Government reference data']"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links[4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 languages by number of native speakers stored in a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = [e.text for e in driver.find_elements(By.TAG_NAME, 'td')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = top [::4][:27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "natives = top [1::4][:27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = {'languages' : languages , 'natives': natives}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(top).sort_values('natives', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['natives'] = df['natives'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(top).sort_values('natives', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterable = df.natives.values\n",
    "\n",
    "def sumar_2(x):\n",
    "    return x+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[922.0, 87.2, 86.6, 85.1]"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(sumar_2, iterable))[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>languages</th>\n",
       "      <th>natives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mandarin Chinese\\n(incl. Standard Chinese, but...</td>\n",
       "      <td>920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>475.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English</td>\n",
       "      <td>373.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hindi\\n(excl. Urdu)</td>\n",
       "      <td>344.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bengali</td>\n",
       "      <td>234.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Portuguese</td>\n",
       "      <td>232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Russian</td>\n",
       "      <td>154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Yue Chinese\\n(incl. Cantonese)</td>\n",
       "      <td>85.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>84.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Marathi</td>\n",
       "      <td>83.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Telugu</td>\n",
       "      <td>82.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>82.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Wu Chinese\\n(incl. Shanghainese)</td>\n",
       "      <td>81.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Korean</td>\n",
       "      <td>81.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>French</td>\n",
       "      <td>79.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Tamil</td>\n",
       "      <td>78.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Standard German</td>\n",
       "      <td>75.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Egyptian Spoken Arabic\\n(excl. Saʽidi Arabic)</td>\n",
       "      <td>74.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Urdu\\n(excl. Hindi)</td>\n",
       "      <td>70.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            languages  natives\n",
       "0   Mandarin Chinese\\n(incl. Standard Chinese, but...    920.0\n",
       "1                                             Spanish    475.0\n",
       "2                                             English    373.0\n",
       "3                                 Hindi\\n(excl. Urdu)    344.0\n",
       "4                                             Bengali    234.0\n",
       "5                                          Portuguese    232.0\n",
       "6                                             Russian    154.0\n",
       "7                                            Japanese    125.0\n",
       "8                      Yue Chinese\\n(incl. Cantonese)     85.2\n",
       "9                                          Vietnamese     84.6\n",
       "10                                            Marathi     83.1\n",
       "11                                             Telugu     82.7\n",
       "12                                            Turkish     82.2\n",
       "13                   Wu Chinese\\n(incl. Shanghainese)     81.8\n",
       "14                                             Korean     81.7\n",
       "15                                             French     79.9\n",
       "16                                              Tamil     78.4\n",
       "17                                    Standard German     75.6\n",
       "18      Egyptian Spoken Arabic\\n(excl. Saʽidi Arabic)     74.8\n",
       "19                                Urdu\\n(excl. Hindi)     70.2"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('natives', ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape a certain number of tweets of a given Twitter account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMDB's Top 250 data (movie name, Initial release, director name and stars) as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "url = 'https://www.imdb.com/chart/top'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = [e.text for e in driver.find_elements(By.XPATH, '//td[@class=\"titleColumn\"]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = [e[:3].strip().replace('.','') for e in top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [e.split('.')[1] for e in top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [e.split('(')[0].strip() for e in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [],
   "source": [
    "release = [e[-6:].replace('(','').replace(')','') for e in top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars = [e.text for e in driver.find_elements(By.XPATH, '//td[@class=\"ratingColumn imdbRating\"]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {\n",
    "'ranking':ranking,\n",
    "'names':names,\n",
    "'release':release,\n",
    "'stars':stars    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranking</th>\n",
       "      <th>names</th>\n",
       "      <th>release</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>1994</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>2008</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The Godfather Part II</td>\n",
       "      <td>1974</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>1957</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ranking                     names release stars\n",
       "0       1  The Shawshank Redemption    1994   9.2\n",
       "1       2             The Godfather    1972   9.2\n",
       "2       3           The Dark Knight    2008   9.0\n",
       "3       4     The Godfather Part II    1974   9.0\n",
       "4       5              12 Angry Men    1957   9.0"
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Movie name, year and a brief summary of the top 10 random movies (IMDB) as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the url you will scrape in this exercise\n",
    "url = 'http://www.imdb.com/chart/top'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranking</th>\n",
       "      <th>names</th>\n",
       "      <th>release</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>248</td>\n",
       "      <td>Aladdin</td>\n",
       "      <td>1992</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>181</td>\n",
       "      <td>Harry Potter and the Deathly Hallows: Part 2</td>\n",
       "      <td>2011</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>170</td>\n",
       "      <td>Fargo</td>\n",
       "      <td>1996</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>114</td>\n",
       "      <td>A Separation</td>\n",
       "      <td>2011</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>107</td>\n",
       "      <td>Scarface</td>\n",
       "      <td>1983</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>82</td>\n",
       "      <td>Your Name</td>\n",
       "      <td>2016</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>85</td>\n",
       "      <td>Requiem for a Dream</td>\n",
       "      <td>2000</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>182</td>\n",
       "      <td>On the Waterfront</td>\n",
       "      <td>1954</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>141</td>\n",
       "      <td>The Sixth Sense</td>\n",
       "      <td>1999</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>132</td>\n",
       "      <td>Green Book</td>\n",
       "      <td>2018</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ranking                                         names release stars\n",
       "247     248                                       Aladdin    1992   8.0\n",
       "180     181  Harry Potter and the Deathly Hallows: Part 2    2011   8.1\n",
       "169     170                                         Fargo    1996   8.1\n",
       "113     114                                  A Separation    2011   8.2\n",
       "106     107                                      Scarface    1983   8.2\n",
       "81       82                                     Your Name    2016   8.3\n",
       "84       85                           Requiem for a Dream    2000   8.3\n",
       "181     182                             On the Waterfront    1954   8.1\n",
       "140     141                               The Sixth Sense    1999   8.2\n",
       "131     132                                    Green Book    2018   8.2"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the live weather report (temperature, wind speed, description and weather) of a given city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the city:Paris\n"
     ]
    }
   ],
   "source": [
    "#https://openweathermap.org/current\n",
    "city = city=input('Enter the city:')\n",
    "url = 'http://api.openweathermap.org/data/2.5/weather?'+'q='+city+'&APPID=b35975e18dc93725acb092f7272cc6b8&units=metric'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Book name,price and stock availability as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise. \n",
    "# It is a fictional bookstore created to be scraped. \n",
    "PATH = ChromeDriverManager().install()\n",
    "\n",
    "driver=webdriver.Chrome(PATH)\n",
    "\n",
    "url = 'http://books.toscrape.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = [e.text for e in driver.find_elements(By.TAG_NAME, 'h3')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = [e.text[:6] for e in driver.find_elements(By.XPATH, '//div[@class=\"product_price\"]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = [e.text for e in driver.find_elements(By.XPATH, '//p[@class=\"instock availability\"]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {\n",
    "    'book':book,\n",
    "    'price':price,\n",
    "    'stock':stock\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>price</th>\n",
       "      <th>stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Light in the ...</td>\n",
       "      <td>£51.77</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tipping the Velvet</td>\n",
       "      <td>£53.74</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Soumission</td>\n",
       "      <td>£50.10</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>£47.82</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sapiens: A Brief History ...</td>\n",
       "      <td>£54.23</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Requiem Red</td>\n",
       "      <td>£22.65</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Dirty Little Secrets ...</td>\n",
       "      <td>£33.34</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Coming Woman: A ...</td>\n",
       "      <td>£17.93</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Boys in the ...</td>\n",
       "      <td>£22.60</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Black Maria</td>\n",
       "      <td>£52.15</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Starving Hearts (Triangular Trade ...</td>\n",
       "      <td>£13.99</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Shakespeare's Sonnets</td>\n",
       "      <td>£20.66</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Set Me Free</td>\n",
       "      <td>£17.46</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Scott Pilgrim's Precious Little ...</td>\n",
       "      <td>£52.29</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Rip it Up and ...</td>\n",
       "      <td>£35.02</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Our Band Could Be ...</td>\n",
       "      <td>£57.25</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Olio</td>\n",
       "      <td>£23.88</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Mesaerion: The Best Science ...</td>\n",
       "      <td>£37.59</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Libertarianism for Beginners</td>\n",
       "      <td>£51.33</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>It's Only the Himalayas</td>\n",
       "      <td>£45.17</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     book   price     stock\n",
       "0                      A Light in the ...  £51.77  In stock\n",
       "1                      Tipping the Velvet  £53.74  In stock\n",
       "2                              Soumission  £50.10  In stock\n",
       "3                           Sharp Objects  £47.82  In stock\n",
       "4            Sapiens: A Brief History ...  £54.23  In stock\n",
       "5                         The Requiem Red  £22.65  In stock\n",
       "6            The Dirty Little Secrets ...  £33.34  In stock\n",
       "7                 The Coming Woman: A ...  £17.93  In stock\n",
       "8                     The Boys in the ...  £22.60  In stock\n",
       "9                         The Black Maria  £52.15  In stock\n",
       "10  Starving Hearts (Triangular Trade ...  £13.99  In stock\n",
       "11                  Shakespeare's Sonnets  £20.66  In stock\n",
       "12                            Set Me Free  £17.46  In stock\n",
       "13    Scott Pilgrim's Precious Little ...  £52.29  In stock\n",
       "14                      Rip it Up and ...  £35.02  In stock\n",
       "15                  Our Band Could Be ...  £57.25  In stock\n",
       "16                                   Olio  £23.88  In stock\n",
       "17        Mesaerion: The Best Science ...  £37.59  In stock\n",
       "18           Libertarianism for Beginners  £51.33  In stock\n",
       "19                It's Only the Himalayas  £45.17  In stock"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
